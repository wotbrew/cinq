---

lmdb root variable scan does not use bufcmp-ksv, only tx variables do

---

lmdb create-relvar can throw map-resized

---

Index max/min top-k

---

Identifiers

Variable = keyword, optionally qualified
Index = pair [?variable ?keyword]

---

Primary, Unique, FK

Before a complete picture is formed around schema, start with discrete operations that do the work on the db.

;; might be nice, to have a data literal for 'index key', including 'relvar' - this makes more sense when considering foreign keys.
(c/add-index db [:customers :birthdate])

;; index can then be looked up with the db using both components, or rel using second component
(get db [:customers :birthdate]) == (get-in db [:customers :birthdate])

;; associate :unique true with an existing index, throw if already a value on insert
;; throw if index does not exist
(c/add-unique-index db [:customers :email] true)

;; perhaps if indexes were created either as unique or not, rather than toggled - we can use a different type.
;; I think a unique index can behave like an eager clojure map of key -> val, rather than key -> rel (for all keys).
;; i.e (-> db :customers :email (get "foo@bar.com)) returns {:email "foo@bar.com", ...}"
;;     (-> db :customers :email (put "foo@bar.com" {:email "foo@bar.com", ...})) (assert on :email = key).
;; can then do put-if-absent, upd, upd-or-merge etc etc.

;; add a foreign key into the
(foreign-key db [:orders :customer-id] [:customers :id] {:on-delete :cascade})

- On insert test if value when given is a hit for the supplied index.
- When :customer is deleted, a cascades array is checked to :cascade or :set-nil the referenced order.
  Behaviour if not specified is to crash (as a constraint would be invalidated)

Like create-index, these functions create and return an index. In the case of foreign keys, it may only attach or modify metadata associated with an existing index (that it is a foreign key).

---

Implicit group

(q [f foo] (c/count))

if let/proj/where/join/scan-src/group-expr/order-expr expr expects grouping, add it if is not already present

---

Spilling

spilled merge join
(q [c customers
    :join! [o orders (= o:customer-id c:customer-id]]
    [c o])

spilled group by
(q [c customers
    :group! [firstname c:firstname]]
    [firstname (c/count)])

spilled sorts
(q [c customers
    :order! [c:firstname :desc]]
    c:id)

---

CinqDynamicBigRecord
- used if map is big
- actual hash table with lazy value loads

---

CinqDynamicList
- perhaps for large lists, lazy decoding would be helpful

---

CinqDynamicSet
(same as maps)

---

Record specialisation (structs)

(c/defrecord Customer [a b c d e f])

adds an actual defrecord, with a type hint.
record name is mapped to a layout (array of name, type)

layouts are stored in the symbol table
records are stored as layout value* buffers

(q [^Customer c customers])
 provides a layout hint to (scan customers) so that decoder can be specialised

if layout hint not matched adapt to the record using map->X ?
Or perhaps emitted/hinted type should be an interface, which can have an adapter for a lazy record

---

Hardening

- variable limit (LMDB)
- symbol limit (warn and degrade?)

---

Datalog

For recursive queries, I think datalog would be a better fit than the sql-style cinq q.

Datalog definition will rely on semantics suggestive of 'applying a relation as a function'. This invokes a generative binding mode

(require '[com.wotbrew.cinq.datalog :as dlog])

form (dlog/q ?selection ?projection)

standard relation application is generative, either a from (first application) or a join.

(dlog/q [(customers {?id :id})] ?id))
=>
(q [{?id :id} (generate customers {})] ?id)

a generate call on a returns a relation, It is implemented by relations and by functions.

(dlog/q
 [(customers {?id :id, ?firstname :firstname})
  (= ?id 42)]
 ?firstname)
=>
(q [{?id :id, ?firstname :firstname} (generate customers {})
    :join [_ (generate = ?id 42)]
  ?firstname)

Top level relation application will be turned into (generate) calls, but for common predicates - or predicates that are flagged as such
can get optimised away into :when clauses.

Normal relations will accept unary argument with a map of bindings for generate. Datalog rules will accept positional arguments.

(q [{?id :id} (generate customers {})
    :when (= ?id 42)])

;; dependent joins can be optimised into joins by rewriting generate calls
(dlog/q
 [(customers {?id :id})
  (orders {?id :customer-id, :order-id ?o})]
 [?id ?o]
 )
;; =>
(q [{?id :id} (generate customers {})
    :join [{?o :order-id} (generate orders {?id :customer-id})]
  [?id ?o])

rule:
(generate ?relvar {}) == ?relvar
(q [{?id :id} customers
    :join [_ (generate orders {?id :customer-id})]
  [?id o:order-id])

rule:
(generate ?relvar {?var ?att ...})
:join [x ?relvar (= ?var x:?att)]

RULEDEF

Rules look like lambdas, arity-overload used for multiple bodies. Can be defined inline or def'd like views.

(dlog/q
   [(dlog/r ancestor
     ([?a ?b]
      (parent {:child ?a, :parent ?b}))
     ([?a ?c]
      (parent {:child ?a, :parent ?b})
      (ancestor ?b ?c)))
    (ancestor ?a "bob")]
    ?a
   )

is transformed to a cte expression.

(c/cte [ancestor (c/q [p parent] [p:child p:parent])
        ancestor (c/q [[?a ?b] ancestor
                       :join [[?b ?c] ancestor (= ?b ?c)])])]
  (c/q [[?a ?c0] ancestor
        :when (= ?c0 "bob")]
    ?a))

PROBLEM: macros, or, not etc?

---

Destructure numeric key

(q [[a b] foo] [a b])

vector destructures should leave a special (nth-lookup) form in the scan so that we choose nth over get or dispatch at runtime based
on whether associative?

---

Views / Rules

(c/defview ancestor [parent]
  parent
  (c/q [[a b] ancestor
        [c d] ancestor
        :when (= b c)]
        [a b]))

defines macro-like the ra
[:union parent $join]

Problems:
 - hygiene, do we need to gensym and unquote?
 - Perhaps all unresolvable globally unqualified symbols get renamed to gensym?

usage

(cte [parent2 [["bob" "phil"]]
      ancestor (ancestor parent2)]
   ancestor)

[:cte [[parent ...], [ancestor [:cte [[ancestor [:union parent $join]]]]]]]

rules:

flatten unions into same bind
flatten cte into cte

---

Non materialized CTE views

---

Mutual recursion

Not supported at the moment. How to make that fast?

Non recursivity carries to dependents, if a query/view is only dependent on non recursive queries it itself is non recursive
this would be a planner / ana change

---

Interrupted checks

Currently, if the loop gets out of control (CTE?) you are screwed as there are no interrupt checks.
This will likely be even more important later when you are scanning 2TB LMDB relations.

Putting interrupt checks naively on the main loop does come with a fairly significant perf cost or around 5%.

If reads were buffered this cost may go down? Or if we go down the columnar route we can put the check at vector points

---

Nil as a record

Yay or nay, I expect a few things might be trickier if nils are allowed (we'd need to box to disambiguate for e.g lmdb delete return)

---

LMDB map size

map resize lock, guarantee exclusivity!
ReadWrite lock, write lock used when map needs resizing (and possibly DDL?),
read lock used for lmdb transactions (read/write) consider fairness barging.
for now all transactions completely lock the database!

---

Test db per index

This could mean a some multiple of the number of tables as opened dbis and extra per transaction overhead. Test though, might be fine.
If we have a problem consider prefixing keys with a single byte (0 == table), (1+) == index. Can have a max of 254 indexes per table.

---

Escape analysis

If columns do not escape a query, we do not need to copy them into heap memory.

We are already doing this a little bit to choose an unsafe top-level type for records.

- if captured by a 'build' such as group/join hash table, we still can keep refs to native mem
- if used in an expression (or intermediate) expression that might escape (due to side effect or return from query, or embedding in a return)
  we need to copy

---

immu / bitemp

- immutable relvar
  implies system_from, system_to cols
  update = cut
  delete = cut

  implies $now denormalized index for each var. use c/latest to return a new db/tx which wraps all relvars
  implies $now index for each index (-> db c/latest :foo :id (get 42))

- bitemporal relvar

  implies system_from, system_to, valid_from, valid_to cols
  update = cut
  delete = cut

  implies $now denormalized index for each var. use c/latest to return a new db/tx which wraps all relvars
  implies $now index for each index (-> db c/latest :foo :id (get 42))

---

javascript

- queries emit a lot of code, what to do about that?
- indexeddb rather than lmdb
- async transactions / reads
- conditional compilation and specialisation based on prim types would not be present

---

Index intersection

(c/merge (c/get idx0 42) (c/range idx2 < 42))

Add a rsn scan interface method to indexes to do some int-intersection

---

Composite indexes

- lists / vectors should be ok?
- what does index-key look like
- how does partial index query work
- how are these encoded correctly

---

Hash only indexes

- indexing maps and sets will give you hash lookups but no range queries (obviously)
- prefix coding a hash (find algo that preserves unorderedness of structures)
- should sorted maps / sets get special treatment? i.e these could get a their own typeid?

---

Constraints

Unique (and primary?)
Foreign key
Schema

Encoded as data, saved in variables table

(c/create-relvar db :foo schema) supply initial schema

(c/set-schema relvar schema)
;; throw if cannot enforce

(c/drop-schema relvar)
;; wild west

upserts, insert-ignore etc possible with primary/unique

---

auto-incr

if named attribute can be set to reflect the rsn automatically e.g (c/auto-increment relvar :customer-id)

---

extended destructuring

current limitations

- nesting/composites, e.g [[a b]], {[x, y] :z}
- lookup syms as bare symbols in bind e.g (c/q [a:b coll] a:b)

Currently bind does not follow clj destructuring, as maps do not have a seq path for example

---

'in transaction dvar'

if in a transaction already, root var reads should not implicitly open read/write transaction

e.g (def ^:dynamic *transactions* {})

if-some [ tx (*transactions (.-db relvar)) ] proxy transaction variable instead

this can also help with nested transactions, throwing a nice error if opening a write tx inside a read tx

---

scan chunking

there is a lot of virtual call overhead calling .apply per-tuple.

we could permit buffering some number of tuples before calling .apply

- filtering can set bits in a bitmap
- apply can capture the loop with the reduced checks
- apply can take an array and a len parameter

in the case of native, you can .apply to an lmdb cursor, and specialise the loop, including binary filters.

---

prim maps for integer joins

joins could get specialised hash multimap for long keys. common case if we have auto-incr, sql data.



